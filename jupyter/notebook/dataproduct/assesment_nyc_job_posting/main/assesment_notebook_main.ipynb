{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding required packages\n",
    "import findspark\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make pyspark importable as a regular library\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pyspark related package\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import col, when, avg, round, rank, isnan\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data profile Function Imported\n"
     ]
    }
   ],
   "source": [
    "%run /notebook/dataproduct/assesment_nyc_job_posting/lib/data_profiling_transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPI Transformations Imported\n"
     ]
    }
   ],
   "source": [
    "%run /notebook/dataproduct/assesment_nyc_job_posting/lib/kpi_transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Imported\n"
     ]
    }
   ],
   "source": [
    "%run /notebook/dataproduct/assesment_nyc_job_posting/utils/spark_session.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local System Configuration\n",
    "# Total Memory = 16GB\n",
    "# Total Cores = 10\n",
    "\n",
    "def get_spark_conf():\n",
    "    # Configure Spark settings\n",
    "    spark_conf = SparkConf()\n",
    "    spark_conf.set(\"spark.executor.instances\", \"4\") # 4 instance per node\n",
    "\n",
    "    # Set the number of executor cores\n",
    "    spark_conf.set(\"spark.executor.cores\", \"1\")  # Use 1 cores per executor\n",
    "\n",
    "    # Set the executor memory\n",
    "    spark_conf.set(\"spark.executor.memory\", \"1g\")  # Use 1GB memory per executor\n",
    "\n",
    "    # Set the driver memory\n",
    "    spark_conf.set(\"spark.driver.memory\", \"2g\")    # Use 2GB memory for the driver\n",
    "    \n",
    "    return spark_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Listing the columns based on its type\n",
    "# def get_col_type_dict(df):\n",
    "#     col_type_dict = {}\n",
    "\n",
    "#     for col_name, col_type in df.dtypes:\n",
    "#         if col_type in col_type_dict.keys():\n",
    "#             col_type_dict[col_type].append(col_name)\n",
    "#         else:\n",
    "#             col_type_dict[col_type] = [col_name]\n",
    "\n",
    "#     return col_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profile(df):\n",
    "    \n",
    "    print(\"Starting Data Profiling\")\n",
    "    print(\"Schema of the dataset\")\n",
    "    \n",
    "    #getting the schema\n",
    "    df.printSchema()\n",
    "    \n",
    "    ## Display the first few rows of the DataFrame\n",
    "    display(df.limit(10))\n",
    "    \n",
    "    # Getting counts\n",
    "    total_count = df.count()\n",
    "    print(f\"Total Records: {total_count}\")\n",
    "    \n",
    "    print(\"Getting missing value counts\")\n",
    "    missing_value_counts = calculate_missing_value_counts(df)\n",
    "    display(missing_value_counts)\n",
    "    \n",
    "    print(\"Getting numerical status\")\n",
    "    numerical_columns = [col_name for col_name, col_type in df.dtypes if col_type in [\"int\", \"double\", \"float\"]]\n",
    "    summary_stats = calculate_summary_stats(df, numerical_columns)\n",
    "    display(summary_stats)\n",
    "    \n",
    "    print(\"Getting categorical columns\") \n",
    "    # Most of the time categorical column should be string type but for this analysis -\n",
    "    # assuming that categorical columns can be any type.\n",
    "    distinct_threshold=10\n",
    "    for col_name in df.columns:\n",
    "        is_categorical_cond, distinct_values, top_values = profile_categorical_column(df, col_name)\n",
    "        if is_categorical_cond:\n",
    "            print(f\"Column: {col_name}\")\n",
    "            print(f\"Distinct Values: {distinct_values}\")\n",
    "            print(\"Top Values:\")\n",
    "            top_values.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_kpi(df):        \n",
    "    # Salary range is linked with salary frequency. \n",
    "    # To get any metrics which depends on salary we need to have salary in same frequency.    \n",
    "    print(\"Preparing Data for KPI\")\n",
    "    kpi_pre_df = df.withColumn(\"Annual Salary From\",\n",
    "                       when(col(\"Salary Frequency\") == \"Hourly\", col(\"Salary Range From\") * 2080)  # Assuming 2080 work hours per year\n",
    "                       .when(col(\"Salary Frequency\") == \"Weekly\", col(\"Salary Range From\") * 52)\n",
    "                       .when(col(\"Salary Frequency\") == \"Daily\", col(\"Salary Range From\") * 260)  # Assuming 5 workdays per week\n",
    "                       .otherwise(col(\"Salary Range From\")))\n",
    "    \n",
    "    kpi_df = kpi_pre_df.withColumn(\"Annual Salary To\",\n",
    "                       when(col(\"Salary Frequency\") == \"Hourly\", col(\"Salary Range To\") * 2080)\n",
    "                       .when(col(\"Salary Frequency\") == \"Weekly\", col(\"Salary Range To\") * 52)\n",
    "                       .when(col(\"Salary Frequency\") == \"Daily\", col(\"Salary Range To\") * 260)\n",
    "                       .otherwise(col(\"Salary Range To\")))\n",
    "    \n",
    "    \n",
    "    print(\"Getting KPIs\")\n",
    "    print(\"Top 10 jobs posting per category\")\n",
    "    category_counts = get_top10_job_posting_per_cat(kpi_df)\n",
    "    category_counts.show(truncate=False)\n",
    "    \n",
    "    print(\"The salary distribution per job category\")\n",
    "    salary_distribution = get_sal_dist_per_cat(kpi_df)\n",
    "    salary_distribution.show(truncate=False)\n",
    "    \n",
    "    print(\"The job posting having the highest salary per agency\")\n",
    "    max_sal_per_agency_df = get_highes_sal_per_cat(kpi_df)\n",
    "    max_sal_per_agency_df.show(truncate=False)\n",
    "    \n",
    "    #KPI5: Whats the job positings average salary per agency for the last 2 years\n",
    "    print(\"The average salary per agency for the last 2 years\")\n",
    "    last_n_year = 2\n",
    "    avg_salary_df = get_avg_sal_per_agency_last_n_year(kpi_df,last_n_year)\n",
    "    avg_salary_df.show(truncate=False)\n",
    "\n",
    "    # KPI6 6: What are the highest paid skills in the US market?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    job_name = 'nyc_assesment'\n",
    "    \n",
    "    #setting spark conf before creating spark session\n",
    "    spark_conf = get_spark_conf()\n",
    "    \n",
    "    # Create a SparkSession with the configured settings\n",
    "    spark = get_spark_session(spark_conf, job_name)\n",
    "    \n",
    "    # Listing all the spark conf\n",
    "    spark.sparkContext.getConf().getAll()\n",
    "    \n",
    "    # setting spark conf for analysis\n",
    "    spark.conf.set('spark.sql.repl.eagerEval.enabled',True)\n",
    "    \n",
    "    #reading dataset\n",
    "    # adding escape charater after data profiling the data \n",
    "    df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True, inferSchema=True, escape='\"')\n",
    "    \n",
    "    # reducing the shuffle partition to 4 \n",
    "    # reason 1 data size is very less\n",
    "    # reason 2 to use all the availble cores\n",
    "    spark.conf.set('spark.sql.shuffle.partitions',4)\n",
    "    \n",
    "    # Creating data profile\n",
    "    data_profile(df)\n",
    "    \n",
    "    # Prepreparing data for KPI\n",
    "    # Need to implement\n",
    "    \n",
    "    # Writing prepared and cleaned data \n",
    "    # Needt to implement\n",
    "    \n",
    "    # Showing KPIs\n",
    "    #show_kpi(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Profiling\n",
      "Schema of the dataset\n",
      "root\n",
      " |-- Job ID: integer (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: integer (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: double (nullable = true)\n",
      " |-- Salary Range To: double (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: timestamp (nullable = true)\n",
      " |-- Post Until: timestamp (nullable = true)\n",
      " |-- Posting Updated: timestamp (nullable = true)\n",
      " |-- Process Date: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Job ID</th><th>Agency</th><th>Posting Type</th><th># Of Positions</th><th>Business Title</th><th>Civil Service Title</th><th>Title Code No</th><th>Level</th><th>Job Category</th><th>Full-Time/Part-Time indicator</th><th>Salary Range From</th><th>Salary Range To</th><th>Salary Frequency</th><th>Work Location</th><th>Division/Work Unit</th><th>Job Description</th><th>Minimum Qual Requirements</th><th>Preferred Skills</th><th>Additional Information</th><th>To Apply</th><th>Hours/Shift</th><th>Work Location 1</th><th>Recruitment Contact</th><th>Residency Requirement</th><th>Posting Date</th><th>Post Until</th><th>Posting Updated</th><th>Process Date</th></tr>\n",
       "<tr><td>381492</td><td>NYC HOUSING AUTHO...</td><td>Internal</td><td>2</td><td>Community Associate</td><td>COMMUNITY ASSOCIATE</td><td>56057</td><td>0</td><td>Policy, Research ...</td><td>null</td><td>52000.0</td><td>61936.0</td><td>Annual</td><td>Visual Assessment...</td><td>Lead Hazard Contr...</td><td>The New York City...</td><td>Qualification Req...</td><td>1.  Experience wi...</td><td>NYCHA employees a...</td><td>Click the &quot;Apply ...</td><td>null</td><td>null</td><td>null</td><td>NYCHA has no resi...</td><td>2019-05-10 00:00:00</td><td>null</td><td>2019-07-05 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381492</td><td>NYC HOUSING AUTHO...</td><td>External</td><td>2</td><td>Community Associate</td><td>COMMUNITY ASSOCIATE</td><td>56057</td><td>0</td><td>Policy, Research ...</td><td>null</td><td>52000.0</td><td>61936.0</td><td>Annual</td><td>Visual Assessment...</td><td>Lead Hazard Contr...</td><td>The New York City...</td><td>Qualification Req...</td><td>1.  Experience wi...</td><td>NYCHA employees a...</td><td>Click the &quot;Apply ...</td><td>null</td><td>null</td><td>null</td><td>NYCHA has no resi...</td><td>2019-05-10 00:00:00</td><td>null</td><td>2019-07-05 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381752</td><td>DEPT OF ENVIRONME...</td><td>Internal</td><td>1</td><td>Associate Public ...</td><td>ASSOCIATE PUBLIC ...</td><td>31220</td><td>1</td><td>Health Public Saf...</td><td>F</td><td>58677.0</td><td>91199.0</td><td>Annual</td><td>96-05 Horace Hard...</td><td>Environmental Hea...</td><td>The NYC Departmen...</td><td>1. A baccalaureat...</td><td>â€¢ Excellent int...</td><td>Appointments are ...</td><td>Click &quot;Apply Now&quot;...</td><td>40 hours per week...</td><td>Owls Head Wastewa...</td><td>null</td><td>New York City res...</td><td>2019-01-29 00:00:00</td><td>null</td><td>2019-10-07 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381752</td><td>DEPT OF ENVIRONME...</td><td>External</td><td>1</td><td>Associate Public ...</td><td>ASSOCIATE PUBLIC ...</td><td>31220</td><td>1</td><td>Health Public Saf...</td><td>F</td><td>58677.0</td><td>91199.0</td><td>Annual</td><td>96-05 Horace Hard...</td><td>Environmental Hea...</td><td>The NYC Departmen...</td><td>1. A baccalaureat...</td><td>â€¢ Excellent int...</td><td>Appointments are ...</td><td>Click &quot;Apply Now&quot;...</td><td>40 hours per week...</td><td>Owls Head Wastewa...</td><td>null</td><td>New York City res...</td><td>2019-01-29 00:00:00</td><td>null</td><td>2019-10-07 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381848</td><td>NYC HOUSING AUTHO...</td><td>Internal</td><td>1</td><td>Director, Lead Ha...</td><td>DIRECTOR OF CONTR...</td><td>80287</td><td>M4</td><td>Public Safety, In...</td><td>null</td><td>78574.0</td><td>202744.0</td><td>Annual</td><td>Lead Hazard - Off...</td><td>Lead Hazard Contr...</td><td>Please read this ...</td><td>A Baccalaureate d...</td><td>â€¢ Integrity â€“...</td><td>NYCHA employees a...</td><td>Click the &quot;Apply ...</td><td>null</td><td>null</td><td>null</td><td>NYCHA has no resi...</td><td>2019-01-29 00:00:00</td><td>null</td><td>2019-04-24 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381848</td><td>NYC HOUSING AUTHO...</td><td>External</td><td>1</td><td>Director, Lead Ha...</td><td>DIRECTOR OF CONTR...</td><td>80287</td><td>M4</td><td>Public Safety, In...</td><td>null</td><td>78574.0</td><td>202744.0</td><td>Annual</td><td>Lead Hazard - Off...</td><td>Lead Hazard Contr...</td><td>Please read this ...</td><td>A Baccalaureate d...</td><td>â€¢ Integrity â€“...</td><td>NYCHA employees a...</td><td>Click the &quot;Apply ...</td><td>null</td><td>null</td><td>null</td><td>NYCHA has no resi...</td><td>2019-01-29 00:00:00</td><td>null</td><td>2019-04-24 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381982</td><td>ADMIN FOR CHILDRE...</td><td>Internal</td><td>1</td><td>Director of Security</td><td>DIRECTOR OF SECUR...</td><td>70822</td><td>M1</td><td>Public Safety, In...</td><td>F</td><td>56990.0</td><td>115000.0</td><td>Annual</td><td>150 William Stree...</td><td>Facilities (Admin)</td><td>The New York City...</td><td>1. A baccalaureat...</td><td>The preferred can...</td><td>Section 424-A of ...</td><td>Click on the &quot;App...</td><td>null</td><td>null</td><td>null</td><td>New York City res...</td><td>2019-02-05 00:00:00</td><td>null</td><td>2019-12-10 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>381982</td><td>ADMIN FOR CHILDRE...</td><td>External</td><td>1</td><td>Director of Security</td><td>DIRECTOR OF SECUR...</td><td>70822</td><td>M1</td><td>Public Safety, In...</td><td>F</td><td>56990.0</td><td>115000.0</td><td>Annual</td><td>150 William Stree...</td><td>Facilities (Admin)</td><td>The New York City...</td><td>1. A baccalaureat...</td><td>The preferred can...</td><td>Section 424-A of ...</td><td>Click on the &quot;App...</td><td>null</td><td>null</td><td>null</td><td>New York City res...</td><td>2019-02-05 00:00:00</td><td>null</td><td>2019-12-10 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>382050</td><td>DEPT OF ENVIRONME...</td><td>Internal</td><td>10</td><td>City Seasonal Aide</td><td>CITY SEASONAL AIDE</td><td>91406</td><td>0</td><td>Administration &amp; ...</td><td>F</td><td>15.0</td><td>18.77</td><td>Hourly</td><td>59-17 Junction Bl...</td><td>Dept of Environme...</td><td>The NYC Departmen...</td><td>While there are n...</td><td>1.\tOffice Automat...</td><td>Appointments are ...</td><td>To apply click th...</td><td>35 hour week</td><td>59-17 Junction Bl...</td><td>null</td><td>New York City res...</td><td>2019-02-08 00:00:00</td><td>null</td><td>2019-12-11 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "<tr><td>382050</td><td>DEPT OF ENVIRONME...</td><td>External</td><td>10</td><td>City Seasonal Aide</td><td>CITY SEASONAL AIDE</td><td>91406</td><td>0</td><td>Administration &amp; ...</td><td>F</td><td>15.0</td><td>18.77</td><td>Hourly</td><td>59-17 Junction Bl...</td><td>Dept of Environme...</td><td>The NYC Departmen...</td><td>While there are n...</td><td>1.\tOffice Automat...</td><td>Appointments are ...</td><td>To apply click th...</td><td>35 hour week</td><td>59-17 Junction Bl...</td><td>null</td><td>New York City res...</td><td>2019-02-08 00:00:00</td><td>null</td><td>2019-12-11 00:00:00</td><td>2019-12-17 00:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+--------------------+------------+--------------+--------------------+--------------------+-------------+-----+--------------------+-----------------------------+-----------------+---------------+----------------+--------------------+--------------------+--------------------+-------------------------+--------------------+----------------------+--------------------+--------------------+--------------------+-------------------+---------------------+-------------------+-------------------+-------------------+-------------------+\n",
       "|Job ID|              Agency|Posting Type|# Of Positions|      Business Title| Civil Service Title|Title Code No|Level|        Job Category|Full-Time/Part-Time indicator|Salary Range From|Salary Range To|Salary Frequency|       Work Location|  Division/Work Unit|     Job Description|Minimum Qual Requirements|    Preferred Skills|Additional Information|            To Apply|         Hours/Shift|     Work Location 1|Recruitment Contact|Residency Requirement|       Posting Date|         Post Until|    Posting Updated|       Process Date|\n",
       "+------+--------------------+------------+--------------+--------------------+--------------------+-------------+-----+--------------------+-----------------------------+-----------------+---------------+----------------+--------------------+--------------------+--------------------+-------------------------+--------------------+----------------------+--------------------+--------------------+--------------------+-------------------+---------------------+-------------------+-------------------+-------------------+-------------------+\n",
       "|420781|DEPT OF HEALTH/ME...|    External|             2|Application Devel...|COLLEGE AIDE (ALL...|        10209|    1|Technology, Data ...|                            F|             15.5|          16.19|          Hourly|421 East 26th Str...|          OCME-Admin|The Office of Chi...|     For Assignment Le...|Experience with C...|  1.\tSelected candi...|TO APPLY, PLEASE ...|                null|                null|               null| New York City res...|2019-12-03 00:00:00|               null|2019-12-03 00:00:00|2019-12-17 00:00:00|\n",
       "|420781|DEPT OF HEALTH/ME...|    Internal|             2|Application Devel...|COLLEGE AIDE (ALL...|        10209|    1|Technology, Data ...|                            F|             15.5|          16.19|          Hourly|421 East 26th Str...|          OCME-Admin|The Office of Chi...|     For Assignment Le...|Experience with C...|  1.\tSelected candi...|TO APPLY, PLEASE ...|                null|                null|               null| New York City res...|2019-12-03 00:00:00|               null|2019-12-03 00:00:00|2019-12-17 00:00:00|\n",
       "|420784|HRA/DEPT OF SOCIA...|    Internal|             1|EXECUTIVE DIRECTO...|COMPUTER SYSTEMS ...|        10050|   M3|Technology, Data ...|                            F|          69940.0|       139426.0|          Annual|        15 Metrotech|Mgmt Information ...|Information Techn...|     1. A master's deg...|â€¢ Extensive exp...|  **LOAN FORGIVENES...|APPLICANTS MUST B...|     Managerial Flex|                null|               null| New York City Res...|2019-10-28 00:00:00|               null|2019-10-28 00:00:00|2019-12-17 00:00:00|\n",
       "|420786|OFF OF PAYROLL AD...|    Internal|             1|Help Desk Level 1...|  CLERICAL ASSOCIATE|        10251|    2|Technology, Data ...|                            F|          32850.0|        48940.0|          Annual|    5 Manhattan West|Citywide User Sup...|The Office of Pay...|     Qualification Req...|â€¢\tBasic knowled...|                  null|Current NYC emplo...| 35 hours weekly/Day|5 Manhattan West,...|               null| New York City res...|2019-10-29 00:00:00|               null|2019-11-06 00:00:00|2019-12-17 00:00:00|\n",
       "|420798|DEPARTMENT OF FIN...|    Internal|             1|Property Valuatio...|CITY RESEARCH SCI...|        21744|    2|Policy, Research ...|                            F|          75504.0|        86830.0|          Annual|66 John Street, N...|Property Modeling...|NYC Department of...|     1.  For Assignmen...|â€¢\tExperience wi...|  In compliance wit...|Click the \"Apply ...|Unless otherwise ...|66 John Street, N...|               null| New York City res...|2019-12-04 00:00:00|2019-12-18 00:00:00|2019-12-02 00:00:00|2019-12-17 00:00:00|\n",
       "|420798|DEPARTMENT OF FIN...|    External|             1|Property Valuatio...|CITY RESEARCH SCI...|        21744|    2|Policy, Research ...|                            F|          75504.0|        86830.0|          Annual|66 John Street, N...|Property Modeling...|NYC Department of...|     1.  For Assignmen...|â€¢\tExperience wi...|  In compliance wit...|Click the \"Apply ...|Unless otherwise ...|66 John Street, N...|               null| New York City res...|2019-12-04 00:00:00|2019-12-18 00:00:00|2019-12-02 00:00:00|2019-12-17 00:00:00|\n",
       "|420803|OFFICE OF MANAGEM...|    Internal|             1|College Aide  Ass...|COLLEGE AIDE (ALL...|        10209|    1|Engineering, Arch...|                            P|             15.5|           19.9|          Hourly|255 Greenwich Street|Interns/Hourly Em...|DIVISION:\t\tTechni...|     For Assignment Le...|QUALIFICATIONS:  ...|  REQUIREMENTS:  Co...|For City employee...|                null|255 Greenwich Street|               null| New York City res...|2019-10-28 00:00:00|               null|2019-10-28 00:00:00|2019-12-17 00:00:00|\n",
       "|420803|OFFICE OF MANAGEM...|    External|             1|College Aide  Ass...|COLLEGE AIDE (ALL...|        10209|    1|Engineering, Arch...|                            P|             15.5|           19.9|          Hourly|255 Greenwich Street|Interns/Hourly Em...|DIVISION:\t\tTechni...|     For Assignment Le...|QUALIFICATIONS:  ...|  REQUIREMENTS:  Co...|For City employee...|                null|255 Greenwich Street|               null| New York City res...|2019-10-28 00:00:00|               null|2019-10-28 00:00:00|2019-12-17 00:00:00|\n",
       "|420804|TAXI & LIMOUSINE ...|    External|             2|Prosecuting Attorney|AGENCY ATTORNEY I...|        30086|    0|       Legal Affairs|                            F|          62397.0|        71757.0|          Annual|31-00 47 Ave, 3 F...|Prosecution Division|The New York City...|     Graduation from a...|Interested candid...|                  null|Click, \"APPLY NOW...|                null|31-00 47 Ave, 3 F...|               null| New York City res...|2019-10-29 00:00:00|               null|2019-10-29 00:00:00|2019-12-17 00:00:00|\n",
       "|420804|TAXI & LIMOUSINE ...|    Internal|             2|Prosecuting Attorney|AGENCY ATTORNEY I...|        30086|    0|       Legal Affairs|                            F|          62397.0|        71757.0|          Annual|31-00 47 Ave, 3 F...|Prosecution Division|The New York City...|     Graduation from a...|Interested candid...|                  null|Click, \"APPLY NOW...|                null|31-00 47 Ave, 3 F...|               null| New York City res...|2019-10-29 00:00:00|               null|2019-10-29 00:00:00|2019-12-17 00:00:00|\n",
       "+------+--------------------+------------+--------------+--------------------+--------------------+-------------+-----+--------------------+-----------------------------+-----------------+---------------+----------------+--------------------+--------------------+--------------------+-------------------------+--------------------+----------------------+--------------------+--------------------+--------------------+-------------------+---------------------+-------------------+-------------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 2946\n",
      "Getting missing value counts\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve 'isnan(`Posting Date`)' due to data type mismatch: argument 1 requires (double or float) type, however, '`Posting Date`' is of timestamp type.;;\\n'Aggregate [count(CASE WHEN ((((Contains(cast(Job ID#335 as string), None) || Contains(cast(Job ID#335 as string), NULL)) || (Job ID#335 = cast( as int))) || isnull(Job ID#335)) || isnan(cast(Job ID#335 as double))) THEN Job ID END) AS Job ID_missing#651L, count(CASE WHEN ((((Contains(Agency#336, None) || Contains(Agency#336, NULL)) || (Agency#336 = )) || isnull(Agency#336)) || isnan(cast(Agency#336 as double))) THEN Agency END) AS Agency_missing#653L, count(CASE WHEN ((((Contains(Posting Type#337, None) || Contains(Posting Type#337, NULL)) || (Posting Type#337 = )) || isnull(Posting Type#337)) || isnan(cast(Posting Type#337 as double))) THEN Posting Type END) AS Posting Type_missing#655L, count(CASE WHEN ((((Contains(cast(# Of Positions#338 as string), None) || Contains(cast(# Of Positions#338 as string), NULL)) || (# Of Positions#338 = cast( as int))) || isnull(# Of Positions#338)) || isnan(cast(# Of Positions#338 as double))) THEN # Of Positions END) AS # Of Positions_missing#657L, count(CASE WHEN ((((Contains(Business Title#339, None) || Contains(Business Title#339, NULL)) || (Business Title#339 = )) || isnull(Business Title#339)) || isnan(cast(Business Title#339 as double))) THEN Business Title END) AS Business Title_missing#659L, count(CASE WHEN ((((Contains(Civil Service Title#340, None) || Contains(Civil Service Title#340, NULL)) || (Civil Service Title#340 = )) || isnull(Civil Service Title#340)) || isnan(cast(Civil Service Title#340 as double))) THEN Civil Service Title END) AS Civil Service Title_missing#661L, count(CASE WHEN ((((Contains(Title Code No#341, None) || Contains(Title Code No#341, NULL)) || (Title Code No#341 = )) || isnull(Title Code No#341)) || isnan(cast(Title Code No#341 as double))) THEN Title Code No END) AS Title Code No_missing#663L, count(CASE WHEN ((((Contains(Level#342, None) || Contains(Level#342, NULL)) || (Level#342 = )) || isnull(Level#342)) || isnan(cast(Level#342 as double))) THEN Level END) AS Level_missing#665L, count(CASE WHEN ((((Contains(Job Category#343, None) || Contains(Job Category#343, NULL)) || (Job Category#343 = )) || isnull(Job Category#343)) || isnan(cast(Job Category#343 as double))) THEN Job Category END) AS Job Category_missing#667L, count(CASE WHEN ((((Contains(Full-Time/Part-Time indicator#344, None) || Contains(Full-Time/Part-Time indicator#344, NULL)) || (Full-Time/Part-Time indicator#344 = )) || isnull(Full-Time/Part-Time indicator#344)) || isnan(cast(Full-Time/Part-Time indicator#344 as double))) THEN Full-Time/Part-Time indicator END) AS Full-Time/Part-Time indicator_missing#669L, count(CASE WHEN ((((Contains(cast(Salary Range From#345 as string), None) || Contains(cast(Salary Range From#345 as string), NULL)) || (Salary Range From#345 = cast( as double))) || isnull(Salary Range From#345)) || isnan(Salary Range From#345)) THEN Salary Range From END) AS Salary Range From_missing#671L, count(CASE WHEN ((((Contains(cast(Salary Range To#346 as string), None) || Contains(cast(Salary Range To#346 as string), NULL)) || (Salary Range To#346 = cast( as double))) || isnull(Salary Range To#346)) || isnan(Salary Range To#346)) THEN Salary Range To END) AS Salary Range To_missing#673L, count(CASE WHEN ((((Contains(Salary Frequency#347, None) || Contains(Salary Frequency#347, NULL)) || (Salary Frequency#347 = )) || isnull(Salary Frequency#347)) || isnan(cast(Salary Frequency#347 as double))) THEN Salary Frequency END) AS Salary Frequency_missing#675L, count(CASE WHEN ((((Contains(Work Location#348, None) || Contains(Work Location#348, NULL)) || (Work Location#348 = )) || isnull(Work Location#348)) || isnan(cast(Work Location#348 as double))) THEN Work Location END) AS Work Location_missing#677L, count(CASE WHEN ((((Contains(Division/Work Unit#349, None) || Contains(Division/Work Unit#349, NULL)) || (Division/Work Unit#349 = )) || isnull(Division/Work Unit#349)) || isnan(cast(Division/Work Unit#349 as double))) THEN Division/Work Unit END) AS Division/Work Unit_missing#679L, count(CASE WHEN ((((Contains(Job Description#350, None) || Contains(Job Description#350, NULL)) || (Job Description#350 = )) || isnull(Job Description#350)) || isnan(cast(Job Description#350 as double))) THEN Job Description END) AS Job Description_missing#681L, count(CASE WHEN ((((Contains(Minimum Qual Requirements#351, None) || Contains(Minimum Qual Requirements#351, NULL)) || (Minimum Qual Requirements#351 = )) || isnull(Minimum Qual Requirements#351)) || isnan(cast(Minimum Qual Requirements#351 as double))) THEN Minimum Qual Requirements END) AS Minimum Qual Requirements_missing#683L, count(CASE WHEN ((((Contains(Preferred Skills#352, None) || Contains(Preferred Skills#352, NULL)) || (Preferred Skills#352 = )) || isnull(Preferred Skills#352)) || isnan(cast(Preferred Skills#352 as double))) THEN Preferred Skills END) AS Preferred Skills_missing#685L, count(CASE WHEN ((((Contains(Additional Information#353, None) || Contains(Additional Information#353, NULL)) || (Additional Information#353 = )) || isnull(Additional Information#353)) || isnan(cast(Additional Information#353 as double))) THEN Additional Information END) AS Additional Information_missing#687L, count(CASE WHEN ((((Contains(To Apply#354, None) || Contains(To Apply#354, NULL)) || (To Apply#354 = )) || isnull(To Apply#354)) || isnan(cast(To Apply#354 as double))) THEN To Apply END) AS To Apply_missing#689L, count(CASE WHEN ((((Contains(Hours/Shift#355, None) || Contains(Hours/Shift#355, NULL)) || (Hours/Shift#355 = )) || isnull(Hours/Shift#355)) || isnan(cast(Hours/Shift#355 as double))) THEN Hours/Shift END) AS Hours/Shift_missing#691L, count(CASE WHEN ((((Contains(Work Location 1#356, None) || Contains(Work Location 1#356, NULL)) || (Work Location 1#356 = )) || isnull(Work Location 1#356)) || isnan(cast(Work Location 1#356 as double))) THEN Work Location 1 END) AS Work Location 1_missing#693L, count(CASE WHEN ((((Contains(Recruitment Contact#357, None) || Contains(Recruitment Contact#357, NULL)) || (Recruitment Contact#357 = )) || isnull(Recruitment Contact#357)) || isnan(cast(Recruitment Contact#357 as double))) THEN Recruitment Contact END) AS Recruitment Contact_missing#695L, count(CASE WHEN ((((Contains(Residency Requirement#358, None) || Contains(Residency Requirement#358, NULL)) || (Residency Requirement#358 = )) || isnull(Residency Requirement#358)) || isnan(cast(Residency Requirement#358 as double))) THEN Residency Requirement END) AS Residency Requirement_missing#697L, ... 4 more fields]\\n+- Relation[Job ID#335,Agency#336,Posting Type#337,# Of Positions#338,Business Title#339,Civil Service Title#340,Title Code No#341,Level#342,Job Category#343,Full-Time/Part-Time indicator#344,Salary Range From#345,Salary Range To#346,Salary Frequency#347,Work Location#348,Division/Work Unit#349,Job Description#350,Minimum Qual Requirements#351,Preferred Skills#352,Additional Information#353,To Apply#354,Hours/Shift#355,Work Location 1#356,Recruitment Contact#357,Residency Requirement#358,... 4 more fields] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o221.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve 'isnan(`Posting Date`)' due to data type mismatch: argument 1 requires (double or float) type, however, '`Posting Date`' is of timestamp type.;;\n'Aggregate [count(CASE WHEN ((((Contains(cast(Job ID#335 as string), None) || Contains(cast(Job ID#335 as string), NULL)) || (Job ID#335 = cast( as int))) || isnull(Job ID#335)) || isnan(cast(Job ID#335 as double))) THEN Job ID END) AS Job ID_missing#651L, count(CASE WHEN ((((Contains(Agency#336, None) || Contains(Agency#336, NULL)) || (Agency#336 = )) || isnull(Agency#336)) || isnan(cast(Agency#336 as double))) THEN Agency END) AS Agency_missing#653L, count(CASE WHEN ((((Contains(Posting Type#337, None) || Contains(Posting Type#337, NULL)) || (Posting Type#337 = )) || isnull(Posting Type#337)) || isnan(cast(Posting Type#337 as double))) THEN Posting Type END) AS Posting Type_missing#655L, count(CASE WHEN ((((Contains(cast(# Of Positions#338 as string), None) || Contains(cast(# Of Positions#338 as string), NULL)) || (# Of Positions#338 = cast( as int))) || isnull(# Of Positions#338)) || isnan(cast(# Of Positions#338 as double))) THEN # Of Positions END) AS # Of Positions_missing#657L, count(CASE WHEN ((((Contains(Business Title#339, None) || Contains(Business Title#339, NULL)) || (Business Title#339 = )) || isnull(Business Title#339)) || isnan(cast(Business Title#339 as double))) THEN Business Title END) AS Business Title_missing#659L, count(CASE WHEN ((((Contains(Civil Service Title#340, None) || Contains(Civil Service Title#340, NULL)) || (Civil Service Title#340 = )) || isnull(Civil Service Title#340)) || isnan(cast(Civil Service Title#340 as double))) THEN Civil Service Title END) AS Civil Service Title_missing#661L, count(CASE WHEN ((((Contains(Title Code No#341, None) || Contains(Title Code No#341, NULL)) || (Title Code No#341 = )) || isnull(Title Code No#341)) || isnan(cast(Title Code No#341 as double))) THEN Title Code No END) AS Title Code No_missing#663L, count(CASE WHEN ((((Contains(Level#342, None) || Contains(Level#342, NULL)) || (Level#342 = )) || isnull(Level#342)) || isnan(cast(Level#342 as double))) THEN Level END) AS Level_missing#665L, count(CASE WHEN ((((Contains(Job Category#343, None) || Contains(Job Category#343, NULL)) || (Job Category#343 = )) || isnull(Job Category#343)) || isnan(cast(Job Category#343 as double))) THEN Job Category END) AS Job Category_missing#667L, count(CASE WHEN ((((Contains(Full-Time/Part-Time indicator#344, None) || Contains(Full-Time/Part-Time indicator#344, NULL)) || (Full-Time/Part-Time indicator#344 = )) || isnull(Full-Time/Part-Time indicator#344)) || isnan(cast(Full-Time/Part-Time indicator#344 as double))) THEN Full-Time/Part-Time indicator END) AS Full-Time/Part-Time indicator_missing#669L, count(CASE WHEN ((((Contains(cast(Salary Range From#345 as string), None) || Contains(cast(Salary Range From#345 as string), NULL)) || (Salary Range From#345 = cast( as double))) || isnull(Salary Range From#345)) || isnan(Salary Range From#345)) THEN Salary Range From END) AS Salary Range From_missing#671L, count(CASE WHEN ((((Contains(cast(Salary Range To#346 as string), None) || Contains(cast(Salary Range To#346 as string), NULL)) || (Salary Range To#346 = cast( as double))) || isnull(Salary Range To#346)) || isnan(Salary Range To#346)) THEN Salary Range To END) AS Salary Range To_missing#673L, count(CASE WHEN ((((Contains(Salary Frequency#347, None) || Contains(Salary Frequency#347, NULL)) || (Salary Frequency#347 = )) || isnull(Salary Frequency#347)) || isnan(cast(Salary Frequency#347 as double))) THEN Salary Frequency END) AS Salary Frequency_missing#675L, count(CASE WHEN ((((Contains(Work Location#348, None) || Contains(Work Location#348, NULL)) || (Work Location#348 = )) || isnull(Work Location#348)) || isnan(cast(Work Location#348 as double))) THEN Work Location END) AS Work Location_missing#677L, count(CASE WHEN ((((Contains(Division/Work Unit#349, None) || Contains(Division/Work Unit#349, NULL)) || (Division/Work Unit#349 = )) || isnull(Division/Work Unit#349)) || isnan(cast(Division/Work Unit#349 as double))) THEN Division/Work Unit END) AS Division/Work Unit_missing#679L, count(CASE WHEN ((((Contains(Job Description#350, None) || Contains(Job Description#350, NULL)) || (Job Description#350 = )) || isnull(Job Description#350)) || isnan(cast(Job Description#350 as double))) THEN Job Description END) AS Job Description_missing#681L, count(CASE WHEN ((((Contains(Minimum Qual Requirements#351, None) || Contains(Minimum Qual Requirements#351, NULL)) || (Minimum Qual Requirements#351 = )) || isnull(Minimum Qual Requirements#351)) || isnan(cast(Minimum Qual Requirements#351 as double))) THEN Minimum Qual Requirements END) AS Minimum Qual Requirements_missing#683L, count(CASE WHEN ((((Contains(Preferred Skills#352, None) || Contains(Preferred Skills#352, NULL)) || (Preferred Skills#352 = )) || isnull(Preferred Skills#352)) || isnan(cast(Preferred Skills#352 as double))) THEN Preferred Skills END) AS Preferred Skills_missing#685L, count(CASE WHEN ((((Contains(Additional Information#353, None) || Contains(Additional Information#353, NULL)) || (Additional Information#353 = )) || isnull(Additional Information#353)) || isnan(cast(Additional Information#353 as double))) THEN Additional Information END) AS Additional Information_missing#687L, count(CASE WHEN ((((Contains(To Apply#354, None) || Contains(To Apply#354, NULL)) || (To Apply#354 = )) || isnull(To Apply#354)) || isnan(cast(To Apply#354 as double))) THEN To Apply END) AS To Apply_missing#689L, count(CASE WHEN ((((Contains(Hours/Shift#355, None) || Contains(Hours/Shift#355, NULL)) || (Hours/Shift#355 = )) || isnull(Hours/Shift#355)) || isnan(cast(Hours/Shift#355 as double))) THEN Hours/Shift END) AS Hours/Shift_missing#691L, count(CASE WHEN ((((Contains(Work Location 1#356, None) || Contains(Work Location 1#356, NULL)) || (Work Location 1#356 = )) || isnull(Work Location 1#356)) || isnan(cast(Work Location 1#356 as double))) THEN Work Location 1 END) AS Work Location 1_missing#693L, count(CASE WHEN ((((Contains(Recruitment Contact#357, None) || Contains(Recruitment Contact#357, NULL)) || (Recruitment Contact#357 = )) || isnull(Recruitment Contact#357)) || isnan(cast(Recruitment Contact#357 as double))) THEN Recruitment Contact END) AS Recruitment Contact_missing#695L, count(CASE WHEN ((((Contains(Residency Requirement#358, None) || Contains(Residency Requirement#358, NULL)) || (Residency Requirement#358 = )) || isnull(Residency Requirement#358)) || isnan(cast(Residency Requirement#358 as double))) THEN Residency Requirement END) AS Residency Requirement_missing#697L, ... 4 more fields]\n+- Relation[Job ID#335,Agency#336,Posting Type#337,# Of Positions#338,Business Title#339,Civil Service Title#340,Title Code No#341,Level#342,Job Category#343,Full-Time/Part-Time indicator#344,Salary Range From#345,Salary Range To#346,Salary Frequency#347,Work Location#348,Division/Work Unit#349,Job Description#350,Minimum Qual Requirements#351,Preferred Skills#352,Additional Information#353,To Apply#354,Hours/Shift#355,Work Location 1#356,Recruitment Contact#357,Residency Requirement#358,... 4 more fields] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:116)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:297)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3412)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1340)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b1e732f76f75>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Creating data profile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdata_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Prepreparing data for KPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-dcc69527cdf9>\u001b[0m in \u001b[0;36mdata_profile\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Getting missing value counts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmissing_value_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_missing_value_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_value_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7953af7693fb>\u001b[0m in \u001b[0;36mcalculate_missing_value_counts\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                   isnan(c), c)).alias(c + \"_missing\"))\n\u001b[0;32m----> 7\u001b[0;31m                        for c in df.columns])\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmissing_value_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \"\"\"\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve 'isnan(`Posting Date`)' due to data type mismatch: argument 1 requires (double or float) type, however, '`Posting Date`' is of timestamp type.;;\\n'Aggregate [count(CASE WHEN ((((Contains(cast(Job ID#335 as string), None) || Contains(cast(Job ID#335 as string), NULL)) || (Job ID#335 = cast( as int))) || isnull(Job ID#335)) || isnan(cast(Job ID#335 as double))) THEN Job ID END) AS Job ID_missing#651L, count(CASE WHEN ((((Contains(Agency#336, None) || Contains(Agency#336, NULL)) || (Agency#336 = )) || isnull(Agency#336)) || isnan(cast(Agency#336 as double))) THEN Agency END) AS Agency_missing#653L, count(CASE WHEN ((((Contains(Posting Type#337, None) || Contains(Posting Type#337, NULL)) || (Posting Type#337 = )) || isnull(Posting Type#337)) || isnan(cast(Posting Type#337 as double))) THEN Posting Type END) AS Posting Type_missing#655L, count(CASE WHEN ((((Contains(cast(# Of Positions#338 as string), None) || Contains(cast(# Of Positions#338 as string), NULL)) || (# Of Positions#338 = cast( as int))) || isnull(# Of Positions#338)) || isnan(cast(# Of Positions#338 as double))) THEN # Of Positions END) AS # Of Positions_missing#657L, count(CASE WHEN ((((Contains(Business Title#339, None) || Contains(Business Title#339, NULL)) || (Business Title#339 = )) || isnull(Business Title#339)) || isnan(cast(Business Title#339 as double))) THEN Business Title END) AS Business Title_missing#659L, count(CASE WHEN ((((Contains(Civil Service Title#340, None) || Contains(Civil Service Title#340, NULL)) || (Civil Service Title#340 = )) || isnull(Civil Service Title#340)) || isnan(cast(Civil Service Title#340 as double))) THEN Civil Service Title END) AS Civil Service Title_missing#661L, count(CASE WHEN ((((Contains(Title Code No#341, None) || Contains(Title Code No#341, NULL)) || (Title Code No#341 = )) || isnull(Title Code No#341)) || isnan(cast(Title Code No#341 as double))) THEN Title Code No END) AS Title Code No_missing#663L, count(CASE WHEN ((((Contains(Level#342, None) || Contains(Level#342, NULL)) || (Level#342 = )) || isnull(Level#342)) || isnan(cast(Level#342 as double))) THEN Level END) AS Level_missing#665L, count(CASE WHEN ((((Contains(Job Category#343, None) || Contains(Job Category#343, NULL)) || (Job Category#343 = )) || isnull(Job Category#343)) || isnan(cast(Job Category#343 as double))) THEN Job Category END) AS Job Category_missing#667L, count(CASE WHEN ((((Contains(Full-Time/Part-Time indicator#344, None) || Contains(Full-Time/Part-Time indicator#344, NULL)) || (Full-Time/Part-Time indicator#344 = )) || isnull(Full-Time/Part-Time indicator#344)) || isnan(cast(Full-Time/Part-Time indicator#344 as double))) THEN Full-Time/Part-Time indicator END) AS Full-Time/Part-Time indicator_missing#669L, count(CASE WHEN ((((Contains(cast(Salary Range From#345 as string), None) || Contains(cast(Salary Range From#345 as string), NULL)) || (Salary Range From#345 = cast( as double))) || isnull(Salary Range From#345)) || isnan(Salary Range From#345)) THEN Salary Range From END) AS Salary Range From_missing#671L, count(CASE WHEN ((((Contains(cast(Salary Range To#346 as string), None) || Contains(cast(Salary Range To#346 as string), NULL)) || (Salary Range To#346 = cast( as double))) || isnull(Salary Range To#346)) || isnan(Salary Range To#346)) THEN Salary Range To END) AS Salary Range To_missing#673L, count(CASE WHEN ((((Contains(Salary Frequency#347, None) || Contains(Salary Frequency#347, NULL)) || (Salary Frequency#347 = )) || isnull(Salary Frequency#347)) || isnan(cast(Salary Frequency#347 as double))) THEN Salary Frequency END) AS Salary Frequency_missing#675L, count(CASE WHEN ((((Contains(Work Location#348, None) || Contains(Work Location#348, NULL)) || (Work Location#348 = )) || isnull(Work Location#348)) || isnan(cast(Work Location#348 as double))) THEN Work Location END) AS Work Location_missing#677L, count(CASE WHEN ((((Contains(Division/Work Unit#349, None) || Contains(Division/Work Unit#349, NULL)) || (Division/Work Unit#349 = )) || isnull(Division/Work Unit#349)) || isnan(cast(Division/Work Unit#349 as double))) THEN Division/Work Unit END) AS Division/Work Unit_missing#679L, count(CASE WHEN ((((Contains(Job Description#350, None) || Contains(Job Description#350, NULL)) || (Job Description#350 = )) || isnull(Job Description#350)) || isnan(cast(Job Description#350 as double))) THEN Job Description END) AS Job Description_missing#681L, count(CASE WHEN ((((Contains(Minimum Qual Requirements#351, None) || Contains(Minimum Qual Requirements#351, NULL)) || (Minimum Qual Requirements#351 = )) || isnull(Minimum Qual Requirements#351)) || isnan(cast(Minimum Qual Requirements#351 as double))) THEN Minimum Qual Requirements END) AS Minimum Qual Requirements_missing#683L, count(CASE WHEN ((((Contains(Preferred Skills#352, None) || Contains(Preferred Skills#352, NULL)) || (Preferred Skills#352 = )) || isnull(Preferred Skills#352)) || isnan(cast(Preferred Skills#352 as double))) THEN Preferred Skills END) AS Preferred Skills_missing#685L, count(CASE WHEN ((((Contains(Additional Information#353, None) || Contains(Additional Information#353, NULL)) || (Additional Information#353 = )) || isnull(Additional Information#353)) || isnan(cast(Additional Information#353 as double))) THEN Additional Information END) AS Additional Information_missing#687L, count(CASE WHEN ((((Contains(To Apply#354, None) || Contains(To Apply#354, NULL)) || (To Apply#354 = )) || isnull(To Apply#354)) || isnan(cast(To Apply#354 as double))) THEN To Apply END) AS To Apply_missing#689L, count(CASE WHEN ((((Contains(Hours/Shift#355, None) || Contains(Hours/Shift#355, NULL)) || (Hours/Shift#355 = )) || isnull(Hours/Shift#355)) || isnan(cast(Hours/Shift#355 as double))) THEN Hours/Shift END) AS Hours/Shift_missing#691L, count(CASE WHEN ((((Contains(Work Location 1#356, None) || Contains(Work Location 1#356, NULL)) || (Work Location 1#356 = )) || isnull(Work Location 1#356)) || isnan(cast(Work Location 1#356 as double))) THEN Work Location 1 END) AS Work Location 1_missing#693L, count(CASE WHEN ((((Contains(Recruitment Contact#357, None) || Contains(Recruitment Contact#357, NULL)) || (Recruitment Contact#357 = )) || isnull(Recruitment Contact#357)) || isnan(cast(Recruitment Contact#357 as double))) THEN Recruitment Contact END) AS Recruitment Contact_missing#695L, count(CASE WHEN ((((Contains(Residency Requirement#358, None) || Contains(Residency Requirement#358, NULL)) || (Residency Requirement#358 = )) || isnull(Residency Requirement#358)) || isnan(cast(Residency Requirement#358 as double))) THEN Residency Requirement END) AS Residency Requirement_missing#697L, ... 4 more fields]\\n+- Relation[Job ID#335,Agency#336,Posting Type#337,# Of Positions#338,Business Title#339,Civil Service Title#340,Title Code No#341,Level#342,Job Category#343,Full-Time/Part-Time indicator#344,Salary Range From#345,Salary Range To#346,Salary Frequency#347,Work Location#348,Division/Work Unit#349,Job Description#350,Minimum Qual Requirements#351,Preferred Skills#352,Additional Information#353,To Apply#354,Hours/Shift#355,Work Location 1#356,Recruitment Contact#357,Residency Requirement#358,... 4 more fields] csv\\n\""
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
