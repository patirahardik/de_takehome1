{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make pyspark importable as a regular library\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_salary(df):\n",
    "# Feature Engineering - Normalization \n",
    "# Normalizing the salary to annual level \n",
    "    normal_pre_df = df.withColumn(\"Annual Salary From\",\n",
    "                       when(col(\"Salary Frequency\") == \"Hourly\", col(\"Salary Range From\") * 2080)  # Assuming 2080 work hours per year\n",
    "                       .when(col(\"Salary Frequency\") == \"Weekly\", col(\"Salary Range From\") * 52)\n",
    "                       .when(col(\"Salary Frequency\") == \"Daily\", col(\"Salary Range From\") * 260)  # Assuming 5 workdays per week\n",
    "                       .otherwise(col(\"Salary Range From\")))\n",
    "\n",
    "    normalized_df = normal_pre_df.withColumn(\"Annual Salary To\",\n",
    "                       when(col(\"Salary Frequency\") == \"Hourly\", col(\"Salary Range To\") * 2080)\n",
    "                       .when(col(\"Salary Frequency\") == \"Weekly\", col(\"Salary Range To\") * 52)\n",
    "                       .when(col(\"Salary Frequency\") == \"Daily\", col(\"Salary Range To\") * 260)\n",
    "                       .otherwise(col(\"Salary Range To\")))\n",
    "    \n",
    "    return normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preparation(df, col_name):\n",
    "    #Cleaning - Remove punctuation\n",
    "    #remove punctuation\n",
    "    rm_punctutation_df = df.withColumn(col_name +'_non_punch',f.coalesce(f.regexp_replace(f.col(col_name), \"[^\\w\\s]+|[ \\t]+$|[\\d]|^[ \\t]\", \"\"),f.lit('')))\n",
    "    \n",
    "    #Tokenization - Split into words\n",
    "    tokenizer = Tokenizer(inputCol=col_name +'_non_punch', outputCol=col_name + '_splitted')\n",
    "    token_df = tokenizer.transform(rm_punctutation_df)\n",
    "       \n",
    "    #Remove Stop words - Remove words which doesn't hold any value\n",
    "    remover = StopWordsRemover(inputCol=col_name + '_splitted',outputCol=col_name + '_removed')\n",
    "    remover_df = remover.transform(token_df)\n",
    "    \n",
    "    #Lemmatization - converting the word into its dictionary form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Define a UDF for lemmatization\n",
    "    def lemmatize_text(words):\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word != '']\n",
    "        return \" \".join(lemmatized_words)\n",
    "\n",
    "    lemmatize_udf = f.udf(lemmatize_text, StringType())\n",
    "    lemmatized_df = remover_df.withColumn(col_name + \"_lemmatized\", lemmatize_udf(remover_df[col_name + '_removed']))\n",
    "    \n",
    "    # droppoing intermediate columns \n",
    "    drop_col_list = [col_name +'_non_punch',col_name + '_splitted',col_name + '_removed']\n",
    "    \n",
    "    clean_df = lemmatized_df.withColumnRenamed(col_name + \"_lemmatized\", col_name + \"_prepared\").drop(*drop_col_list)\n",
    "    \n",
    "    return clean_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Preparation Functions Imported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
